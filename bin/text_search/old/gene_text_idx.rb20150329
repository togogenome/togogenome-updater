#!/usr/bin/env ruby

require 'json'
require 'fileutils'
require "./gene/sparql_odbc.rb"

class GeneTextSearch

  def initialize()
    @stanza_text_dir = '/data/store/rdf/togogenome/text_search/current'
    @gene_text_dir = "#{@stanza_text_dir}/prepare/gene_text_json"
    @gene_uniprot_map = get_gene_uniprot_map("#{@gene_text_dir}/togo_uniprot.json")
  end

  def get_gene_uniprot_map(file)
    STDERR.puts('Start read gene uniprot map file')
    gene_up_map = JSON.parse(File.read(file))
    STDERR.puts('End read gene uniprot map file')
    gene_up_map
  end

  def output_json(gene_text_files, uniprot_text_files)

    STDERR.puts('Start create gene id list')
    gene_id_list = @gene_uniprot_map.keys   
    STDERR.puts('End create gene id list')

    result_hash = {}

    STDERR.puts('Start create gene_id uniprot_ids columns')
    gene_id_list.each do |gene_id|
      gene_hash = {:gene_id => gene_id, :uniprod_ids => @gene_uniprot_map[gene_id].join(',')}
      result_hash[gene_id] = gene_hash 
    end
    STDERR.puts('End create gene_id uniprot_ids columns')

    STDERR.puts('Start create columns link to gene_id')
    gene_text_files.each do |stanza_text_data|
      $stderr.puts("start:#{stanza_text_data}")
      start_rap_time = Time.now
      cnt = 0
      text_data = JSON.parse(File.read("#{@gene_text_dir}/#{stanza_text_data}")) 
      empty_hash = empty_hash(stanza_text_data)
      gene_id_list.each do |gene_id|
        unless text_data[gene_id].nil?
          text_data[gene_id].delete("gene_id")
          result_hash[gene_id].merge!(text_data[gene_id])
        else
          result_hash[gene_id].merge!(empty_hash)
        end 
        # debug
        cnt += 1
        if((cnt % 100000) == 0)
          rap_time = "Time: #{Time.now - start_rap_time}s"
          STDERR.puts cnt.to_s + " " + rap_time
          start_rap_time = Time.now
        end
      end
    end
    STDERR.puts('End create columns link to gene_id')
 
    STDERR.puts('Start create columns link to uniprot_id')
    uniprot_text_files.each do |stanza_text_data|
      $stderr.puts("Start #{stanza_text_data}")
      start_rap_time = Time.now
      cnt = 0
      text_data = JSON.parse(File.read("#{@gene_text_dir}/#{stanza_text_data}")) 
      empty_hash = empty_hash(stanza_text_data)
      gene_id_list.each do |gene_id|
        protein_info = empty_hash.dup
        @gene_uniprot_map[gene_id].each do |uniprot_id|
          unless text_data[uniprot_id].nil?
            protein_info.keys.each do |column|
              protein_info[column] += text_data[uniprot_id][column]
            end
          end 
          result_hash[gene_id].merge!(protein_info)
        end
        # debug
        cnt += 1
        if((cnt % 100000) == 0)
          rap_time = "Time: #{Time.now - start_rap_time}s"
          STDERR.puts cnt.to_s + " " + rap_time
          start_rap_time = Time.now
        end
      end
    end
    STDERR.puts('End create columns link to uniprot_id')

    STDERR.puts('Start output json file')
    puts JSON.pretty_generate(result_hash)
    STDERR.puts('End output json file')
  end
  def empty_hash(query_type)
    #query_name = query_type.sub('_test.json','')
    query_name = query_type.sub('.json','')
    case query_name
    when SPARQL_ODBC::PROTEIN_CROSS_REFERENCES 
      empty_hash = {"up_xref_categories" => "", "up_xref_abbrs" => "", "up_xref_ids" => ""}
    when SPARQL_ODBC::PROTEIN_REFERENCES 
      empty_hash = {"up_ref_pubmed_ids" => "", "up_ref_citation_names" => "", "up_ref_citation_titles" => "", "up_ref_citation_authors" => ""}
    when SPARQL_ODBC::PROTEIN_SEQUENCE_ANNOTANION 
      empty_hash = {"up_seq_anno_parent_labels" => "", "up_seq_anno_labels" => "", "up_seq_anno_comments" => "", "up_seq_anno_feature_ids" => ""}
    when SPARQL_ODBC::PROTEIN_NAMES_GENE_NAMES
      empty_hash = {"up_gene_names" => "", "up_synonyms_names" => "", "up_locus_tags" => "", "up_orf_names" => ""}
    when SPARQL_ODBC::PROTEIN_NAMES_SUMMARY
      empty_hash = {"up_recommended_names" => "", "up_ec_names" => "", "up_alternative_names" => ""}
    when SPARQL_ODBC::PROTEIN_ONTOLOGIES_GO
      empty_hash = {"up_go_names" => ""}
    when SPARQL_ODBC::PROTEIN_ONTOLOGIES_KEYWORDS
      empty_hash = {"up_keyword_root_names" => "", "keyword_names" => ""}
    when SPARQL_ODBC::GENE_ATTRIBUTES
      empty_hash = {"locus_tags" => "", "gene_names" => "", "sequence_labels" => "", "refseq_labels" => "","sequence_organism_names" => ""}
    end
    empty_hash
  end
end

start_time = Time.now

gene_text = GeneTextSearch.new()

gene_text_files = []
gene_text_files.push("gene_attributes.json")
#gene_text_files.push("gene_attributes_test.json")
uniprot_text_files = []
=begin
uniprot_text_files.push("protein_names_gene_name_test.json")
uniprot_text_files.push("protein_names_summary_test.json")
uniprot_text_files.push("protein_ontologies_go_test.json")
uniprot_text_files.push("protein_ontologies_keywords_test.json")
uniprot_text_files.push("protein_sequence_annotation_test.json")
uniprot_text_files.push("protein_references_test.json")
uniprot_text_files.push("protein_cross_references_test.json")
=end
uniprot_text_files.push("protein_names_gene_name.json")
uniprot_text_files.push("protein_names_summary.json")
uniprot_text_files.push("protein_ontologies_go.json")
uniprot_text_files.push("protein_ontologies_keywords.json")
uniprot_text_files.push("protein_sequence_annotation.json")
uniprot_text_files.push("protein_references.json")
uniprot_text_files.push("protein_cross_references.json")

gene_text.output_json(gene_text_files, uniprot_text_files)

STDERR.puts("Total time: #{Time.now - start_time}s")
